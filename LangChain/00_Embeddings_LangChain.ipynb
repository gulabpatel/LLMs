{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulabpatel/LangChain/blob/main/00_Embeddings_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Information Retreival - LangChain\n",
        "- Without Using OpenAI Embeddings\n",
        "- Without OpenAI LLM\n",
        "\n",
        "code walkthrough video: https://www.youtube.com/watch?v=wrD-fZvT6UI"
      ],
      "metadata": {
        "id": "P6xh7KK_e5l9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two Applications:\n",
        "- Text Documents\n",
        "- Multiple PDF Files"
      ],
      "metadata": {
        "id": "3HbUlsp3fS5p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEZmjGQGW1ue"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install huggingface_hub\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get HUGGINGFACEHUB_API_KEY"
      ],
      "metadata": {
        "id": "Ra7uy0RhXd_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "8AZVtuZiW9Il"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Text File"
      ],
      "metadata": {
        "id": "hALLW9fyXWqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
        "res = requests.get(url)\n",
        "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
        "  f.write(res.text)"
      ],
      "metadata": {
        "id": "j9lr1BOMXTVr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Document Loader\n",
        "from langchain.document_loaders import TextLoader\n",
        "loader = TextLoader('./state_of_the_union.txt')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "sVio4mK5XVwR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def wrap_text_preserve_newlines(text, width=110):\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text"
      ],
      "metadata": {
        "id": "rZjjKyi1m_lA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrap_text_preserve_newlines(str(documents[0])))"
      ],
      "metadata": {
        "id": "mV04kCtEm_tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Splitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "_qXNpk8vXlys"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEUp4OtxnuXL",
        "outputId": "1ecbda32-c395-4afc-8f9d-3559ec6b7819"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_HUKypknucr",
        "outputId": "988e6df4-9a3b-4062-b254-90f6197749c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.', metadata={'source': './state_of_the_union.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1]"
      ],
      "metadata": {
        "id": "jkfe4cA3aQqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eaf4184-dd0a-478a-9eda-6900f23187b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters.', metadata={'source': './state_of_the_union.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings"
      ],
      "metadata": {
        "id": "G6HWzhWUaRIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "uctYbK6YXmxI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wS3_6gbXqvE",
        "outputId": "0f86d27e-cbc4-473d-80e6-367ddd55a32d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.9/dist-packages (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
        "from langchain.vectorstores import FAISS\n",
        "db = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "TTg8T2tJXvTI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about the Supreme Court\"\n",
        "docs = db.similarity_search(query)"
      ],
      "metadata": {
        "id": "IYQOej1MpiH2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrap_text_preserve_newlines(str(docs[0].page_content)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7li6KoVpiQh",
        "outputId": "e24558f2-54b8-4656-b182-821c7d117d97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And\n",
            "while you’re at it, pass the Disclose Act so Americans can know who is funding our elections.\n",
            "\n",
            "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an\n",
            "Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer,\n",
            "thank you for your service.\n",
            "\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the\n",
            "United States Supreme Court.\n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our\n",
            "nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create QA Chain"
      ],
      "metadata": {
        "id": "PzWUbpH6bQ2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "rzJnHsJ_bThf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":0, \"max_length\":512})"
      ],
      "metadata": {
        "id": "_IZn8b8Aci4w"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "X2IMgDRGsVV4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about the Supreme Court\"\n",
        "docs = db.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "aemehFTEsVZG",
        "outputId": "e2fc030c-acaf-42ca-8c36-fc2196d94931"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about economy?\"\n",
        "docs = db.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "SVOXzjaNsVb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d6ad469-154e-477b-b032-9b494904954c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Build the economy from the bottom up and the middle out, not from the top down'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LBjTA5TecxqT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with PDF Files"
      ],
      "metadata": {
        "id": "MNdVzDaNe39j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken\n",
        "!pip install unstructured[local-inference]"
      ],
      "metadata": {
        "id": "0NDARXbveTcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "juVVrXsUfybx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "pdf_folder_path = '/content/gdrive/MyDrive/Dataset/data_2/'\n",
        "os.listdir(pdf_folder_path)"
      ],
      "metadata": {
        "id": "3z1YygkktO12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbcfd05-d41c-437b-9429-596a8cef7dc6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['proximalpolicyoptimization.pdf', 'gpt-4.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]\n",
        "loaders"
      ],
      "metadata": {
        "id": "P5lRcsUWtO42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb1fd38-7314-4652-865e-3d1d7c74f1f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7efc56789550>,\n",
              " <langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7efc308e35e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator(\n",
        "    embedding=HuggingFaceEmbeddings(),\n",
        "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders(loaders)"
      ],
      "metadata": {
        "id": "tBsI8myktO8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":0, \"max_length\":512})"
      ],
      "metadata": {
        "id": "7py0d3o5tO_h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "chain = RetrievalQA.from_chain_type(llm=llm, \n",
        "                                    chain_type=\"stuff\", \n",
        "                                    retriever=index.vectorstore.as_retriever(), \n",
        "                                    input_key=\"question\")"
      ],
      "metadata": {
        "id": "31lq4mOdtPDL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run('How was the GPT4all model trained?')"
      ],
      "metadata": {
        "id": "19VMjTc_tPKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b7ca0bc9-a8ff-434f-ffc2-53f06e7da787"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'supervised fine-tuning (SFT): They collect demonstration data, which consists of labeler-written prompts and desired output behavior. This data is used to fine-tune GPT-3 with supervised learning. 2. Reward model (RM) training: They collect comparison data, where a labeler ranks the outputs from several model samples (from best to worst). This data is used to train the reward model. 3. Reinforcement learning using Proximal Policy Optimization (PPO): They opti- mize a policy against the reward model using reinforcement learning. For each new prompt sampled from the dataset, the policy generates an output. The reward model calculates a reward for the output, and the reward is used to update the policy using the PPO algorithm.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run('Who are the authors of GPT4all technical report?')"
      ],
      "metadata": {
        "id": "biOFwTy4tQBE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6c61737b-8ed6-4e8d-9980-4ff74b2669b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Isabella Fulford, Teddy Lee„ Yaniv Markovski, Tolly Powell, Toki Sherbakov, Jessica Shieh, Natalie Staudacher, Preston Tuggle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run('What is the model size of GPT4all?')"
      ],
      "metadata": {
        "id": "MJ_1DvnDgb_X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f3a35ea-daf5-4526-d670-ecbaa31067f8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10,000x less compute than GPT-4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}