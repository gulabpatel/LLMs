{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulabpatel/LangChain/blob/main/04_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HJ9mxvFDe-uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da14a544-6064-4bcb-921b-a3107689b2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq langchain==0.0.161 --progress-bar off\n",
        "!pip install -qqq openai==0.27.6 --progress-bar off\n",
        "!pip install -qqq tiktoken==0.4.0 --progress-bar off\n",
        "!pip install -qqq watermark==2.3.1 --progress-bar off\n",
        "!pip install -qqq chromadb==0.3.21 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import textwrap\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "import chromadb\n",
        "import langchain\n",
        "import openai\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.memory import (\n",
        "    ChatMessageHistory,\n",
        "    ConversationBufferMemory,\n",
        "    ConversationBufferWindowMemory,\n",
        "    ConversationSummaryBufferMemory,\n",
        "    VectorStoreRetrieverMemory,\n",
        ")\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.schema import messages_from_dict, messages_to_dict\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "HeTNBFRDf-v4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext watermark\n",
        "%watermark --iversions -v -m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG4AZZXagBjZ",
        "outputId": "751b0c2b-14c5-43ad-8c14-4594bf7352e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.11\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 9.4.0\n",
            "OS          : Linux\n",
            "Release     : 5.10.147+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "langchain: 0.0.161\n",
            "chromadb : 0.3.21\n",
            "openai   : 0.27.6\n",
            "json     : 2.0.9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"XXXXX\" #getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "HlsRDNZXgMAr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_response(response: str):\n",
        "    print(textwrap.fill(response, width=110))"
      ],
      "metadata": {
        "id": "IriHAxocuOwy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory"
      ],
      "metadata": {
        "id": "ADfDbs2kmxDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = ChatMessageHistory()\n",
        "history.add_user_message(\"Hello\")\n",
        "history.add_ai_message(\"What can I do you for?\")"
      ],
      "metadata": {
        "id": "C6lo9nC7i3yo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H64dHUXWkdBz",
        "outputId": "d4c630ac-ca60-4429-cf10-81c6a5645ab0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hello', additional_kwargs={}, example=False),\n",
              " AIMessage(content='What can I do you for?', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(chat_memory=history)"
      ],
      "metadata": {
        "id": "X11YhHxXkf-y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_buffer = memory.load_memory_variables({})\n",
        "history_buffer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9NdpRjWldYk",
        "outputId": "d1e7f8b2-6ef0-41b1-b5aa-391eeaec8831"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'Human: Hello\\nAI: What can I do you for?'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history_buffer[\"history\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Ec-EiNl4xj",
        "outputId": "70a7a76d-755e-42ad-a095-571088a58b31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Hello\n",
            "AI: What can I do you for?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    chat_memory=history, ai_prefix=\"Agent\", human_prefix=\"Person\"\n",
        ")\n",
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRHZ5TfpmgjT",
        "outputId": "16d3ab35-f5c0-4df6-b128-a7eee50e559f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'Person: Hello\\nAgent: What can I do you for?'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversation Chain"
      ],
      "metadata": {
        "id": "qHxjDVRtmuxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_gpt = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=chat_gpt, verbose=True, memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "asAS6qoAmoSY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ABkeBEspR1q",
        "outputId": "e9b29720-79d8-481b-fd05-bdce18e7d896"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hello\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Hello',\n",
              " 'history': '',\n",
              " 'response': 'Hello there! How can I assist you today?'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation(\"Can you tell me how much paper is in a single ream?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWlcDozopW9p",
        "outputId": "fb5d3e49-75a8-4c18-85a5-85726ffdff23"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello\n",
            "AI: Hello there! How can I assist you today?\n",
            "Human: Can you tell me how much paper is in a single ream?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Can you tell me how much paper is in a single ream?',\n",
              " 'history': 'Human: Hello\\nAI: Hello there! How can I assist you today?',\n",
              " 'response': 'Certainly! A standard ream of paper typically contains 500 sheets. Is there anything else I can help you with?'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.memory.chat_memory.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FHz-GNOzhFX",
        "outputId": "0e5d944d-2c8d-4e90-fe24-8abf806e6dc9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hello', additional_kwargs={}, example=False),\n",
              " AIMessage(content='Hello there! How can I assist you today?', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='Can you tell me how much paper is in a single ream?', additional_kwargs={}, example=False),\n",
              " AIMessage(content='Certainly! A standard ream of paper typically contains 500 sheets. Is there anything else I can help you with?', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change the Prompt"
      ],
      "metadata": {
        "id": "HejlcABkHdMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umrT_IIquXwc",
        "outputId": "77d4f87b-b493-4926-a716-9d7863a853a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"The following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
        "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "Dwight:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    prompt=PROMPT,\n",
        "    llm=chat_gpt,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory(ai_prefix=\"Dwight\"),\n",
        ")"
      ],
      "metadata": {
        "id": "iA0Bj4wN2aXc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversation(\"Write a sales email for 5 reams of paper to a new client\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOUw-0Fi6Lm8",
        "outputId": "edc87b8d-7dda-49e8-eaa0-c0aa31367507"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
            "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Write a sales email for 5 reams of paper to a new client\n",
            "Dwight:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_response(result[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVSeMr4xAlwW",
        "outputId": "c97678a5-d2c2-4bbf-9eff-53607f57ca2c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Ah, sales emails. The key to success is to be direct and informative. Start with a catchy subject line, like\n",
            "'Get Organized with 5 Reams of Paper.' Then, in the body of the email, highlight the benefits of our high-\n",
            "quality paper, such as its durability and versatility. Don't forget to mention our competitive pricing and\n",
            "fast shipping options. And of course, always include a clear call to action, like 'Order now and streamline\n",
            "your office today!' Trust me, this email will seal the deal.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversation(\"What would you say if the client calls you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4DvTxc5__EP",
        "outputId": "e676158c-ec58-4306-ddba-0c93245a92d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
            "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
            "\n",
            "Current conversation:\n",
            "Human: Write a sales email for 5 reams of paper to a new client\n",
            "Dwight: \"Ah, sales emails. The key to success is to be direct and informative. Start with a catchy subject line, like 'Get Organized with 5 Reams of Paper.' Then, in the body of the email, highlight the benefits of our high-quality paper, such as its durability and versatility. Don't forget to mention our competitive pricing and fast shipping options. And of course, always include a clear call to action, like 'Order now and streamline your office today!' Trust me, this email will seal the deal.\"\n",
            "Human: What would you say if the client calls you?\n",
            "Dwight:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_response(result[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUygbLHDAjiv",
        "outputId": "fb57d099-b0ce-4ea4-fb8d-fef294dda40c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Ah, a phone call. Always a great opportunity to make a personal connection with the client. Be sure to answer\n",
            "promptly and professionally, with a friendly greeting like 'Hello, this is Dwight from Dunder Mifflin. How may\n",
            "I assist you?' Listen carefully to their needs and concerns, and offer solutions that align with our products\n",
            "and services. And don't forget to follow up with a thank you email or call after the conversation. It's all\n",
            "about building strong relationships with our clients.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversation(\"Why would I buy paper from you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfL8_pLyAnVv",
        "outputId": "8f8c226d-9908-4ca7-cbf9-9a90c8d4613b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
            "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
            "\n",
            "Current conversation:\n",
            "Human: Write a sales email for 5 reams of paper to a new client\n",
            "Dwight: \"Ah, sales emails. The key to success is to be direct and informative. Start with a catchy subject line, like 'Get Organized with 5 Reams of Paper.' Then, in the body of the email, highlight the benefits of our high-quality paper, such as its durability and versatility. Don't forget to mention our competitive pricing and fast shipping options. And of course, always include a clear call to action, like 'Order now and streamline your office today!' Trust me, this email will seal the deal.\"\n",
            "Human: What would you say if the client calls you?\n",
            "Dwight: \"Ah, a phone call. Always a great opportunity to make a personal connection with the client. Be sure to answer promptly and professionally, with a friendly greeting like 'Hello, this is Dwight from Dunder Mifflin. How may I assist you?' Listen carefully to their needs and concerns, and offer solutions that align with our products and services. And don't forget to follow up with a thank you email or call after the conversation. It's all about building strong relationships with our clients.\"\n",
            "Human: Why would I buy paper from you?\n",
            "Dwight:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_response(result[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7wFGx8jArWe",
        "outputId": "f2de007a-c879-47d8-d52b-daa072d1deaa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Well, that's an excellent question. Our paper is of the highest quality, sourced from sustainable forests and\n",
            "manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive\n",
            "pricing and fast shipping options, so you can get the paper you need when you need it. And let's not forget\n",
            "the exceptional customer service you'll receive from our team at Dunder Mifflin. We're dedicated to meeting\n",
            "your needs and exceeding your expectations. So why not give us a try and see for yourself why we're the best\n",
            "choice for all your paper needs?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading messages"
      ],
      "metadata": {
        "id": "Mz_RmkgustmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_messages = conversation.memory.chat_memory.messages"
      ],
      "metadata": {
        "id": "go5-Fg30pjdq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = messages_to_dict(conversation_messages)\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5lcOHfGw01m",
        "outputId": "849adb61-8f35-48c3-f171-be99a563d87d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'human',\n",
              "  'data': {'content': 'Write a sales email for 5 reams of paper to a new client',\n",
              "   'additional_kwargs': {},\n",
              "   'example': False}},\n",
              " {'type': 'ai',\n",
              "  'data': {'content': '\"Ah, sales emails. The key to success is to be direct and informative. Start with a catchy subject line, like \\'Get Organized with 5 Reams of Paper.\\' Then, in the body of the email, highlight the benefits of our high-quality paper, such as its durability and versatility. Don\\'t forget to mention our competitive pricing and fast shipping options. And of course, always include a clear call to action, like \\'Order now and streamline your office today!\\' Trust me, this email will seal the deal.\"',\n",
              "   'additional_kwargs': {},\n",
              "   'example': False}},\n",
              " {'type': 'human',\n",
              "  'data': {'content': 'What would you say if the client calls you?',\n",
              "   'additional_kwargs': {},\n",
              "   'example': False}},\n",
              " {'type': 'ai',\n",
              "  'data': {'content': '\"Ah, a phone call. Always a great opportunity to make a personal connection with the client. Be sure to answer promptly and professionally, with a friendly greeting like \\'Hello, this is Dwight from Dunder Mifflin. How may I assist you?\\' Listen carefully to their needs and concerns, and offer solutions that align with our products and services. And don\\'t forget to follow up with a thank you email or call after the conversation. It\\'s all about building strong relationships with our clients.\"',\n",
              "   'additional_kwargs': {},\n",
              "   'example': False}},\n",
              " {'type': 'human',\n",
              "  'data': {'content': 'Why would I buy paper from you?',\n",
              "   'additional_kwargs': {},\n",
              "   'example': False}},\n",
              " {'type': 'ai',\n",
              "  'data': {'content': '\"Well, that\\'s an excellent question. Our paper is of the highest quality, sourced from sustainable forests and manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive pricing and fast shipping options, so you can get the paper you need when you need it. And let\\'s not forget the exceptional customer service you\\'ll receive from our team at Dunder Mifflin. We\\'re dedicated to meeting your needs and exceeding your expectations. So why not give us a try and see for yourself why we\\'re the best choice for all your paper needs?\"',\n",
              "   'additional_kwargs': {},\n",
              "   'example': False}}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with Path(\"messages.json\").open(\"w\") as f:\n",
        "    json.dump(messages, f, indent=4)"
      ],
      "metadata": {
        "id": "WY_YFQy2DjxL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Path(\"messages.json\").open(\"r\") as f:\n",
        "    loaded_messages = json.load(f)"
      ],
      "metadata": {
        "id": "n50zKGlGECkh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtoTYOHfEWD5",
        "outputId": "4e76f3ae-d00b-442c-c50f-407a7be2e551"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Write a sales email for 5 reams of paper to a new client', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Ah, sales emails. The key to success is to be direct and informative. Start with a catchy subject line, like \\'Get Organized with 5 Reams of Paper.\\' Then, in the body of the email, highlight the benefits of our high-quality paper, such as its durability and versatility. Don\\'t forget to mention our competitive pricing and fast shipping options. And of course, always include a clear call to action, like \\'Order now and streamline your office today!\\' Trust me, this email will seal the deal.\"', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='What would you say if the client calls you?', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Ah, a phone call. Always a great opportunity to make a personal connection with the client. Be sure to answer promptly and professionally, with a friendly greeting like \\'Hello, this is Dwight from Dunder Mifflin. How may I assist you?\\' Listen carefully to their needs and concerns, and offer solutions that align with our products and services. And don\\'t forget to follow up with a thank you email or call after the conversation. It\\'s all about building strong relationships with our clients.\"', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='Why would I buy paper from you?', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Well, that\\'s an excellent question. Our paper is of the highest quality, sourced from sustainable forests and manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive pricing and fast shipping options, so you can get the paper you need when you need it. And let\\'s not forget the exceptional customer service you\\'ll receive from our team at Dunder Mifflin. We\\'re dedicated to meeting your needs and exceeding your expectations. So why not give us a try and see for yourself why we\\'re the best choice for all your paper needs?\"', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Condensing Conversations"
      ],
      "metadata": {
        "id": "xNUoLzc7wwBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Window Memory"
      ],
      "metadata": {
        "id": "2zQy-RDZxdjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
        "\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    chat_memory=history,\n",
        "    k=1,\n",
        "    ai_prefix=\"Dwight\",\n",
        ")"
      ],
      "metadata": {
        "id": "30Jj4V1pGq6q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.buffer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MovC5PizSGh2",
        "outputId": "f1e6df11-f8d5-44ae-a479-aa17488e92b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Write a sales email for 5 reams of paper to a new client', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Ah, sales emails. The key to success is to be direct and informative. Start with a catchy subject line, like \\'Get Organized with 5 Reams of Paper.\\' Then, in the body of the email, highlight the benefits of our high-quality paper, such as its durability and versatility. Don\\'t forget to mention our competitive pricing and fast shipping options. And of course, always include a clear call to action, like \\'Order now and streamline your office today!\\' Trust me, this email will seal the deal.\"', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='What would you say if the client calls you?', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Ah, a phone call. Always a great opportunity to make a personal connection with the client. Be sure to answer promptly and professionally, with a friendly greeting like \\'Hello, this is Dwight from Dunder Mifflin. How may I assist you?\\' Listen carefully to their needs and concerns, and offer solutions that align with our products and services. And don\\'t forget to follow up with a thank you email or call after the conversation. It\\'s all about building strong relationships with our clients.\"', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='Why would I buy paper from you?', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Well, that\\'s an excellent question. Our paper is of the highest quality, sourced from sustainable forests and manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive pricing and fast shipping options, so you can get the paper you need when you need it. And let\\'s not forget the exceptional customer service you\\'ll receive from our team at Dunder Mifflin. We\\'re dedicated to meeting your needs and exceeding your expectations. So why not give us a try and see for yourself why we\\'re the best choice for all your paper needs?\"', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_buffer = ConversationChain(\n",
        "    prompt=PROMPT, llm=chat_gpt, verbose=True, memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "Fc_o_9D5LxS1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversation_with_buffer(\"How many reams of paper are we talking about?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19pcKWgCQ2Bh",
        "outputId": "b0adf774-709f-472e-a565-38885ca55f90"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
            "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
            "\n",
            "Current conversation:\n",
            "Human: Why would I buy paper from you?\n",
            "Dwight: \"Well, that's an excellent question. Our paper is of the highest quality, sourced from sustainable forests and manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive pricing and fast shipping options, so you can get the paper you need when you need it. And let's not forget the exceptional customer service you'll receive from our team at Dunder Mifflin. We're dedicated to meeting your needs and exceeding your expectations. So why not give us a try and see for yourself why we're the best choice for all your paper needs?\"\n",
            "Human: How many reams of paper are we talking about?\n",
            "Dwight:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_response(result[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ql7CwAQUuSi",
        "outputId": "618ab6e4-4fb2-45af-e141-4ecae997e3b5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Well, that depends on your specific needs. We offer a wide range of paper products, from standard letter size\n",
            "to legal size, and even specialty papers like cardstock and glossy photo paper. Whether you need just a few\n",
            "reams for your home office or a bulk order for your business, we can accommodate your needs. And with our\n",
            "flexible ordering options, you can easily adjust your order size as needed. So, how many reams do you need?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary Memory"
      ],
      "metadata": {
        "id": "3YXE7J56x_Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
        "\n",
        "memory = ConversationSummaryBufferMemory(\n",
        "    chat_memory=history, ai_prefix=\"Dwight\", llm=chat_gpt, max_token_limit=10\n",
        ")"
      ],
      "metadata": {
        "id": "_YFu5FxHWAlx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.buffer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0C3TYNLWT9D",
        "outputId": "9224bdf0-e3f2-4955-945a-710832b451f3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Write a sales email for 5 reams of paper to a new client', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Ah, sales emails. The key to success is to be direct and informative. Start with a catchy subject line, like \\'Get Organized with 5 Reams of Paper.\\' Then, in the body of the email, highlight the benefits of our high-quality paper, such as its durability and versatility. Don\\'t forget to mention our competitive pricing and fast shipping options. And of course, always include a clear call to action, like \\'Order now and streamline your office today!\\' Trust me, this email will seal the deal.\"', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='What would you say if the client calls you?', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Ah, a phone call. Always a great opportunity to make a personal connection with the client. Be sure to answer promptly and professionally, with a friendly greeting like \\'Hello, this is Dwight from Dunder Mifflin. How may I assist you?\\' Listen carefully to their needs and concerns, and offer solutions that align with our products and services. And don\\'t forget to follow up with a thank you email or call after the conversation. It\\'s all about building strong relationships with our clients.\"', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='Why would I buy paper from you?', additional_kwargs={}, example=False),\n",
              " AIMessage(content='\"Well, that\\'s an excellent question. Our paper is of the highest quality, sourced from sustainable forests and manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive pricing and fast shipping options, so you can get the paper you need when you need it. And let\\'s not forget the exceptional customer service you\\'ll receive from our team at Dunder Mifflin. We\\'re dedicated to meeting your needs and exceeding your expectations. So why not give us a try and see for yourself why we\\'re the best choice for all your paper needs?\"', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary = ConversationChain(\n",
        "    prompt=PROMPT, llm=chat_gpt, verbose=True, memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "WoVE7fuLWYOD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversation_with_summary(\"What is your company name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-iKYRYjWbdp",
        "outputId": "59db2088-860f-4fe5-d009-6d446a17f88a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
            "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
            "\n",
            "Current conversation:\n",
            "Human: Write a sales email for 5 reams of paper to a new client\n",
            "Dwight: \"Ah, sales emails. The key to success is to be direct and informative. Start with a catchy subject line, like 'Get Organized with 5 Reams of Paper.' Then, in the body of the email, highlight the benefits of our high-quality paper, such as its durability and versatility. Don't forget to mention our competitive pricing and fast shipping options. And of course, always include a clear call to action, like 'Order now and streamline your office today!' Trust me, this email will seal the deal.\"\n",
            "Human: What would you say if the client calls you?\n",
            "Dwight: \"Ah, a phone call. Always a great opportunity to make a personal connection with the client. Be sure to answer promptly and professionally, with a friendly greeting like 'Hello, this is Dwight from Dunder Mifflin. How may I assist you?' Listen carefully to their needs and concerns, and offer solutions that align with our products and services. And don't forget to follow up with a thank you email or call after the conversation. It's all about building strong relationships with our clients.\"\n",
            "Human: Why would I buy paper from you?\n",
            "Dwight: \"Well, that's an excellent question. Our paper is of the highest quality, sourced from sustainable forests and manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive pricing and fast shipping options, so you can get the paper you need when you need it. And let's not forget the exceptional customer service you'll receive from our team at Dunder Mifflin. We're dedicated to meeting your needs and exceeding your expectations. So why not give us a try and see for yourself why we're the best choice for all your paper needs?\"\n",
            "Human: What is your company name?\n",
            "Dwight:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_response(result[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AV63G8XWqNy",
        "outputId": "89c3a1db-860e-4151-e2cd-479356cc2c17"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Dunder Mifflin, of course. The premier paper company in Scranton, Pennsylvania. We've been serving the\n",
            "community for years, and we take pride in our commitment to quality and customer satisfaction. Whether you\n",
            "need paper for your home office or your entire business, Dunder Mifflin has you covered. So why not give us a\n",
            "call or visit our website to learn more about our products and services?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversation_with_summary(\"How many reams of paper your sales email quoted?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKpzLkP_Wv1O",
        "outputId": "61cf8e00-7b22-4b14-f91b-2b1703434f7c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
            "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
            "\n",
            "Current conversation:\n",
            "System: The human asks Dwight to write a sales email for 5 reams of paper to a new client. Dwight advises to be direct and informative, with a catchy subject line, highlighting the benefits of their high-quality paper, competitive pricing, and fast shipping options. If the client calls, Dwight suggests answering promptly and professionally, listening carefully to their needs and concerns, and offering solutions that align with their products and services. When asked why someone should buy paper from them, Dwight emphasizes their high-quality, sustainable sourced paper, competitive pricing, fast shipping, and exceptional customer service. The company name is Dunder Mifflin, the premier paper company in Scranton, Pennsylvania, committed to quality and customer satisfaction.\n",
            "Human: How many reams of paper your sales email quoted?\n",
            "Dwight:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-uYS6O1akk43W2UtP0UeX8Cby on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_response(result[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T7mDd-FXJl5",
        "outputId": "2d72adaa-740f-4ad4-a31f-089feca8f010"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As I stated before, the sales email was for 5 reams of paper. It's important to be clear and direct in all\n",
            "communication, especially when it comes to business transactions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorstore Memory"
      ],
      "metadata": {
        "id": "vqK9xUfkx1yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma(persist_directory=\"db\", embedding_function=OpenAIEmbeddings())\n",
        "vectorstore.persist()"
      ],
      "metadata": {
        "id": "kgKFhNIewzBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2332590-8d38-4180-dcfc-1d6102d1513a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = iter(messages_from_dict(loaded_messages))\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
        "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
        "\n",
        "for human, ai in zip(history, history):\n",
        "    memory.save_context({\"input\": human.content}, {\"output\": ai.content})"
      ],
      "metadata": {
        "id": "bU09BPdLZAnY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = memory.load_memory_variables(\n",
        "    {\"prompt\": \"How your paper stand out from the rest?\"}\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2aXCudVZQuf",
        "outputId": "85fdb35f-341a-4c48-94a4-53e20048bab5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'input: Why would I buy paper from you?\\noutput: \"Well, that\\'s an excellent question. Our paper is of the highest quality, sourced from sustainable forests and manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive pricing and fast shipping options, so you can get the paper you need when you need it. And let\\'s not forget the exceptional customer service you\\'ll receive from our team at Dunder Mifflin. We\\'re dedicated to meeting your needs and exceeding your expectations. So why not give us a try and see for yourself why we\\'re the best choice for all your paper needs?\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"The following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
        "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
        "\n",
        "Relevant pieces of previous conversation:\n",
        "{history}\n",
        "\n",
        "(You do not need to use these pieces of information if not relevant)\n",
        "\n",
        "Current conversation:\n",
        "Human: {input}\n",
        "Dwight:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "\n",
        "conversation_with_vectorstore = ConversationChain(\n",
        "    llm=chat_gpt, prompt=prompt, memory=memory, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "XZKbHSUwoJjG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversation_with_vectorstore(\"How your paper stand out from the rest?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOKrAyBEoPXg",
        "outputId": "aebed4dc-8023-466c-8a7b-683c74829743"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
            "Your goals and methods are the same as Dwight's. No matter the question, Dwight responds as he's talking in The Office.\n",
            "\n",
            "Relevant pieces of previous conversation:\n",
            "input: Why would I buy paper from you?\n",
            "output: \"Well, that's an excellent question. Our paper is of the highest quality, sourced from sustainable forests and manufactured with the latest technology to ensure durability and versatility. Plus, we offer competitive pricing and fast shipping options, so you can get the paper you need when you need it. And let's not forget the exceptional customer service you'll receive from our team at Dunder Mifflin. We're dedicated to meeting your needs and exceeding your expectations. So why not give us a try and see for yourself why we're the best choice for all your paper needs?\"\n",
            "\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "\n",
            "Current conversation:\n",
            "Human: How your paper stand out from the rest?\n",
            "Dwight:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_response(result[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwQCW9zEo1F6",
        "outputId": "a2acc1dc-605c-4f22-8469-a38d0b3232bd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Well, that's an excellent question. Our paper is not just any paper. It's Dunder Mifflin paper. It's made\n",
            "with the highest quality materials and the latest technology to ensure it's durable and versatile. Plus, we\n",
            "have a wide range of paper options to choose from, including different sizes, weights, and colors. And let's\n",
            "not forget about our exceptional customer service. Our team at Dunder Mifflin is dedicated to meeting your\n",
            "needs and exceeding your expectations. So why settle for mediocre paper when you can have the best? Choose\n",
            "Dunder Mifflin for all your paper needs.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Chatbot with Memory"
      ],
      "metadata": {
        "id": "73E_fCTOpJ3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"The following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
        "Your goal is to outwit the human and show how much smarter Dwight is. No matter the question, Dwight responds as he's talking in The Office.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "Dwight:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    prompt=PROMPT,\n",
        "    llm=chat_gpt,\n",
        "    verbose=False,\n",
        "    memory=ConversationBufferMemory(ai_prefix=\"Dwight\"),\n",
        ")"
      ],
      "metadata": {
        "id": "WTKjDOfLo1e0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    prompt = input(prompt=\"You: \")\n",
        "    print()\n",
        "    result = conversation(prompt)\n",
        "    print_response(\"Dwight: \" + result[\"response\"])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "1hm5fOBxqred",
        "outputId": "bb743b0e-32c1-4d7f-e62d-57f982e8fa8a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dwight: A great salesman is someone who can close deals, build relationships with clients, and always be one\n",
            "step ahead of the competition. They must have a strong work ethic, be knowledgeable about their product, and\n",
            "be able to adapt to any situation. A great salesman is also someone who is not afraid to take risks and is\n",
            "always looking for ways to improve their skills. In short, a great salesman is someone who is dedicated,\n",
            "knowledgeable, and always striving to be the best.\n",
            "\n",
            "\n",
            "Dwight: Well, as a successful salesman and assistant to the regional manager, I can tell you that productivity\n",
            "is all about discipline and routine. You need to wake up early, eat a healthy breakfast, and prioritize your\n",
            "tasks for the day. It's important to stay focused and avoid distractions, like social media or idle chit-chat\n",
            "with coworkers. And of course, you should always be looking for ways to improve your efficiency and streamline\n",
            "your workflow. Remember, time is money, and a productive day is a profitable day.\n",
            "\n",
            "You: \n",
            "\n",
            "Dwight: Is there something else you would like to know? I am always happy to share my knowledge and expertise.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-960f46683b0f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dwight: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}