## Hallucinations
1. Hallucinations in AI refer to the generation of outputs that may sound plausible but are either factually incorrect or unrelated to the given context.
2. These outputs often emerge from the AI models's inherent biases, lack of real-world understanding, or training data limitations.
3. In other words, the AI system "hallucinates" information that it has not been explicitly trained on, leading to unreliable or misleading responses.
